<!-- livebook:{"file_entries":[{"file":{"file_system_id":"local","file_system_type":"local","path":"/Users/pswartz/Dropbox/0-Inbox/data-2024-09-02.csv"},"name":"data.csv","type":"file"}]} -->

# RideAlong Prediction Accuracy pt2

```elixir
Mix.install(
  [
    {:kino, "~> 0.13"},
    {:kino_vega_lite, "~> 0.1.13"},
    {:ride_along, path: Path.join(__DIR__, ".."), env: :dev}
  ],
  config_path: Path.join([__DIR__, "..", "config", "config.exs"]),
  start_applications: false
)
```

## Load/Group Data

```elixir
require Explorer.DataFrame, as: DF
alias Explorer.{Duration, Series}
alias VegaLite, as: Vl

df =
  "data.csv"
  |> Kino.FS.file_path()
  |> DF.from_csv!(
    parse_dates: true,
    nil_values: [""],
    dtypes: %{status: :category}
  )
  |> DF.filter(route > 0)

defmodule Support do
  def truncate_to_minute(%DateTime{} = dt) do
    Map.merge(dt, %{second: 0, microsecond: {0, 0}})
  end

  def round_up_to_minute(%DateTime{second: second, microsecond: {microsecond, _precision}} = dt)
      when second > 0 or microsecond > 0 do
    dt
    |> Map.put(:time_zone, "Etc/UTC")
    |> DateTime.add(1, :minute)
    |> Map.merge(%{second: 0, microsecond: {0, 0}})

    dt
  end

  def round_up_to_minute(dt) do
    dt
  end
end
  
:ok
```

<!-- livebook:{"reevaluate_automatically":true} -->

```elixir
Application.ensure_all_started(:kino)
IEx.Helpers.r(RideAlong.EtaCalculator.Model)
IEx.Helpers.r(RideAlong.EtaCalculator.Training)
alias RideAlong.EtaCalculator.Model
alias RideAlong.EtaCalculator.Training

arrival_times = Training.arrival_times(df)

Kino.nothing()
```

<!-- livebook:{"reevaluate_automatically":true} -->

```elixir
alias Explorer.Duration
IEx.Helpers.r(RideAlong.EtaCalculator.Model)
IEx.Helpers.r(RideAlong.EtaCalculator.Training)

training_fields = Model.feature_names()

seed = 4055183217 # Enum.random(0..(Integer.pow(2, 32) - 1))

df = DF.shuffle(df, seed: seed)
df =
  df
  |> DF.join(arrival_times, on: "trip_id")
  |> Training.populate()
  |> DF.mutate(ors_eta: time + %Duration{value: 1_000, precision: :millisecond} * ors_duration)

size = Series.size(df[:time])
validation_size = min(trunc(size * 0.9), 25_000)

train_df = DF.slice(df, validation_size..-1//1)

x =
  train_df
  |> DF.select(training_fields)
  |> Nx.stack(axis: 1)

y = DF.select(train_df, :ors_to_add) |> Nx.concatenate()

opts = Keyword.merge(Training.training_params(), [
  seed: seed
])

IO.puts("About to train (using seed #{seed})...")
model = EXGBoost.train(x, y, opts)
IO.puts("Trained!")

df =
  df
  |> DF.slice(0..(validation_size - 1))

predicted = Training.predict_from_data_frame(model, df)

df = df
  |> DF.put(:model_to_add, predicted)
  |> DF.mutate(
    model: time + %Duration{value: 1_000, precision: :millisecond} * (ors_duration + model_to_add)
  )
  |> DF.discard([:model_to_add])

[model_size: byte_size(EXGBoost.dump_model(model, format: :ubj)) / 1024.0 / 1024.0]
```

## Accuracy Analysis

```elixir
IEx.Helpers.r(RideAlong.EtaCalculator.Training)
fields = [:pick, :ors_eta, :model]
```

<!-- livebook:{"reevaluate_automatically":true} -->

```elixir
quantiles = fn df, field ->
  df = Training.with_accuracy(df, :time, :arrival_time, field, &Training.accuracy/1)

  [five, twenty_five, seventy_five, ninety_five] =
    for q <- [0.05, 0.25, 0.75, 0.95] do
      (Series.quantile(df[:diff], q) / 60) |> Float.round(1)
    end

  DF.new(%{
    :field => ["#{field}"],
    :median => [Float.round(Series.median(df[:diff]) / 60, 1)],
    "50%" => ["#{twenty_five} - #{seventy_five} (#{abs(seventy_five - twenty_five)})"],
    "90%" => ["#{five} - #{ninety_five} (#{abs(ninety_five - five)})"]
  })
end

fields
|> Enum.map(&quantiles.(df, &1))
|> DF.concat_rows()
|> Kino.DataTable.new()
```

<!-- livebook:{"reevaluate_automatically":true} -->

```elixir
accuracy = &Training.accuracy/1

for field <- fields do
  %{
    "field" => "#{field}",
    "accuracy" => Training.overall_accuracy(df, :time, :arrival_time, field, accuracy)[:accuracy][0]
  }
end
|> Kino.DataTable.new(name: "Overall Accuracy %", keys: ["field", "accuracy"])
```

<!-- livebook:{"reevaluate_automatically":true} -->

```elixir
for field <- fields do
  Training.grouped_accuracy(df, :time, :arrival_time, field, accuracy) |> Kino.DataTable.new(name: field)
end
|> Kino.Layout.grid(columns: 2)
```

## Model Parameter Tuning

```elixir
best_result = %{
  opts: [],
  accuracy: 0.0,
  ratio: 0.0
}

df =
  df
  |> DF.slice(0..(validation_size - 1))

results =
  for max_depth <- [9],
      num_boost_rounds <- 1600..2000//100 do
    new_opts = [
      max_depth: max_depth,
      num_boost_rounds: num_boost_rounds,
      seed: seed
    ]

    opts = Keyword.merge(Training.training_params(), new_opts)
    model = EXGBoost.train(x, y, opts)

    predicted = Training.predict_from_data_frame(model, df)

    df =
      df
      |> DF.put(:model_to_add, predicted)
      |> DF.mutate(
        model:
          time +
            %Duration{value: 1_000, precision: :millisecond} * (ors_duration + model_to_add)
      )
      |> DF.discard([:model_to_add])

    overall =
      Training.overall_accuracy(df, :time, :arrival_time, :model, accuracy)[:accuracy][0]

    size_mb = byte_size(EXGBoost.dump_model(model, format: :ubj)) / 1024.0 / 1024.0

    %{
      #opts: Jason.encode!(Map.new(new_opts)),
      max_depth: max_depth,
      num_boost_rounds: num_boost_rounds,
      accuracy: overall,
      model_size: size_mb,
    } |> IO.inspect()
  end

:ok
```

```elixir
Vl.new()
|> Vl.data_from_values(results)
|> Vl.mark(:point, tooltip: [content: :data])
|> Vl.encode_field(:color, "max_depth", type: :nominal)
|> Vl.encode_field(:y, "accuracy", type: :quantitative, scale: [zero: false])
|> Vl.encode_field(:x, "model_size", type: :quantitative)
```

<!-- livebook:{"offset":5755,"stamp":{"token":"XCP.pdCWXtHeMmJ5i8soFsc1rhDSqC1EgryvR2RCS9iL6PvzTPhL5gOHnQH4igsi6kqQIIqgz7IsZeHg47gn7EBCiRfiBuMcwOcvG9um5Q","version":2}} -->
